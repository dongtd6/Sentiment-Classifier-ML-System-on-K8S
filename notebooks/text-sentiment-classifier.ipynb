{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfRsVFF-uwOJ"
      },
      "source": [
        "\n",
        "# **Xây dựng Model phân loại cảm xúc trong văn bản**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: MLFLOW_TRACKING_URI=http://mlflow.tsc.vn\n",
            "env: MLFLOW_TRACKING_USERNAME=user\n",
            "env: MLFLOW_TRACKING_PASSWORD=mH680qJ2pCpH\n"
          ]
        }
      ],
      "source": [
        "%env MLFLOW_TRACKING_URI=http://mlflow.tsc.vn\n",
        "%env MLFLOW_TRACKING_USERNAME=user\n",
        "%env MLFLOW_TRACKING_PASSWORD=mH680qJ2pCpH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr33pOVLDTtW",
        "outputId": "2634c49b-171c-4eec-d5e1-b97e41d1aa33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /home/dongtd6/.local/lib/python3.10/site-packages (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /home/dongtd6/.local/lib/python3.10/site-packages (1.0.2)\n",
            "Requirement already satisfied: joblib in /home/dongtd6/.local/lib/python3.10/site-packages (1.1.0)\n",
            "Requirement already satisfied: mlflow in /home/dongtd6/.local/lib/python3.10/site-packages (3.1.4)\n",
            "Requirement already satisfied: matplotlib in /home/dongtd6/.local/lib/python3.10/site-packages (3.10.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/dongtd6/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dongtd6/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /home/dongtd6/.local/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: gunicorn<24 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (2.0.42)\n",
            "Requirement already satisfied: Flask<4 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (3.1.1)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (20.0.0)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (1.16.4)\n",
            "Requirement already satisfied: graphene<4 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: mlflow-skinny==3.1.4 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (4.14.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (8.2.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (1.34.1)\n",
            "Requirement already satisfied: fastapi<1 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.96.0)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/lib/python3/dist-packages (from mlflow-skinny==3.1.4->mlflow) (5.4.1)\n",
            "Requirement already satisfied: uvicorn<1 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.22.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (4.25.8)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (1.34.1)\n",
            "Requirement already satisfied: packaging<26 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (25.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.5.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (2.31.0)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle<4 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (8.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (1.10.22)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (3.1.45)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from mlflow-skinny==3.1.4->mlflow) (0.60.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/dongtd6/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: tomli in /home/dongtd6/.local/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (2.2.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/lib/python3/dist-packages (from docker<8,>=4.0.0->mlflow) (1.26.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /home/dongtd6/.local/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: greenlet>=1 in /home/dongtd6/.local/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n",
            "Requirement already satisfied: google-auth~=2.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (2.40.3)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==3.1.4->mlflow) (0.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /home/dongtd6/.local/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.4->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /home/dongtd6/.local/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.4->mlflow) (0.55b1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dongtd6/.local/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (3.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (2020.6.20)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.4->mlflow) (3.3)\n",
            "Requirement already satisfied: h11>=0.8 in /home/dongtd6/.local/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==3.1.4->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.4->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dongtd6/.local/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /home/dongtd6/.local/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<1->mlflow-skinny==3.1.4->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<1->mlflow-skinny==3.1.4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/dongtd6/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<1->mlflow-skinny==3.1.4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/dongtd6/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.4->mlflow) (0.6.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn joblib mlflow matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrbb9oUMvCOc"
      },
      "source": [
        "## **1. Import các thư viện cần thiết**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6dJOBvdkCzLd"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m ]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[1;32m     20\u001b[0m     _safe_tags,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
            "File \u001b[0;32msklearn/utils/murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "import os\n",
        "import mlflow # Import MLflow\n",
        "import mlflow.sklearn # Import MLflow Sklearn flavor\n",
        "import matplotlib.pyplot as plt # Import để lưu biểu đồ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymq5ZWfXvLB0"
      },
      "source": [
        "## **2. Tải dữ liệu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FRoKnz7C0Bo",
        "outputId": "a48f6372-c2ab-4ae0-b0da-5358df48257f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã tải dữ liệu thành công!\n",
            "5 dòng đầu tiên của dữ liệu:\n",
            "                       comment label  rate Unnamed: 3\n",
            "0               Áo bao đẹp ạ!!   POS     5        NaN\n",
            "1                  Tuyệt vời !   POS     5        NaN\n",
            "2   2day ao khong giong trong.   NEG     1        NaN\n",
            "3  Mùi thơm,bôi lên da mềm da.   POS     5        NaN\n",
            "4            Vải đẹp, dày dặn.   POS     5        NaN\n",
            "\n",
            "Thông tin dữ liệu:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18183 entries, 0 to 18182\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   comment     18183 non-null  object\n",
            " 1   label       18183 non-null  object\n",
            " 2   rate        18183 non-null  int64 \n",
            " 3   Unnamed: 3  23 non-null     object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 568.3+ KB\n"
          ]
        }
      ],
      "source": [
        "# Định nghĩa đường dẫn tới file CSV\n",
        "file_path = 'data.csv'\n",
        "\n",
        "# Kiểm tra xem file có tồn tại không\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Lỗi: File không tìm thấy tại đường dẫn: {file_path}\")\n",
        "    exit()\n",
        "# Tải dữ liệu từ file CSV vào DataFrame\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"Đã tải dữ liệu thành công!\")\n",
        "    print(\"5 dòng đầu tiên của dữ liệu:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nThông tin dữ liệu:\")\n",
        "    df.info()\n",
        "except Exception as e:\n",
        "    print(f\"Lỗi khi tải dữ liệu: {e}\")\n",
        "    # Thoát nếu không thể tải dữ liệu thực tế\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRnIHUAMvQMi"
      },
      "source": [
        "## **3. Tiền xử lý dữ liệu**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCgEjsBBC3SQ",
        "outputId": "2f913df4-cc10-46f3-d7c2-d159d702558e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Số lượng mẫu sau khi loại bỏ NaN: 18183\n",
            "Phân bố các nhãn:\n",
            "POS    6816\n",
            "NEG    6669\n",
            "NEU    4698\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Loại bỏ các hàng có giá trị NaN trong cột 'comment' hoặc 'label'\n",
        "df.dropna(subset=['comment', 'label'], inplace=True)\n",
        "\n",
        "# Chuyển đổi nhãn về định dạng thống nhất (ví dụ: chữ hoa)\n",
        "df['label'] = df['label'].astype(str).str.upper()\n",
        "\n",
        "print(f\"\\nSố lượng mẫu sau khi loại bỏ NaN: {len(df)}\")\n",
        "print(\"Phân bố các nhãn:\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozzSGXGBvTTB"
      },
      "source": [
        "## **4. Chia tập dữ liệu Training và Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjuRqS49C4XK",
        "outputId": "a23437f2-d779-4f79-a380-ff3e3be602cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số lượng mẫu trong tập huấn luyện: 14546\n",
            "Số lượng mẫu trong tập kiểm tra: 3637\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Định nghĩa features (X) và target (y)\n",
        "X = df['comment']\n",
        "y = df['label']\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "# test_size=0.2 có nghĩa là 20% dữ liệu sẽ được dùng để kiểm tra\n",
        "# random_state để đảm bảo kết quả chia dữ liệu là như nhau mỗi lần chạy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Số lượng mẫu trong tập huấn luyện: {len(X_train)}\")\n",
        "print(f\"Số lượng mẫu trong tập kiểm tra: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMx3heIrvYkV"
      },
      "source": [
        "## **5. Vector hóa văn bản (TF-IDF Vectorization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFU3uxFiC4UU",
        "outputId": "6a24cac5-7b87-45bd-ad7b-3b6f113adbba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kích thước ma trận TF-IDF tập huấn luyện: (14546, 1557)\n",
            "Kích thước ma trận TF-IDF tập kiểm tra: (3637, 1557)\n"
          ]
        }
      ],
      "source": [
        "# --- BẮT ĐẦU MLFLOW RUN ---\n",
        "with mlflow.start_run(run_name=\"Text_Sentiments_Classifier_Run\") as active_run:\n",
        "    run_id = active_run.info.run_id\n",
        "    print(f\"MLflow Run ID: {run_id}\")\n",
        "\n",
        "# Khởi tạo TF-IDF Vectorizer\n",
        "max_features = 5000 # max_features giới hạn số lượng từ/cụm từ độc nhất được xem xét\n",
        "min_df = 5 # min_df bỏ qua các từ xuất hiện quá ít (ví dụ: chỉ 1 lần)\n",
        "stop_words='english' #loại bỏ các từ dừng tiếng Anh\n",
        "\n",
        "# Ghi log các tham số của vectorizer vào MLflow\n",
        "mlflow.log_param(\"vectorizer_max_features\", max_features)\n",
        "mlflow.log_param(\"vectorizer_min_df\", min_df)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=max_features, min_df=min_df, stop_words=None) # Giữ stop_words=None nếu dữ liệu tiếng Việt\n",
        "\n",
        "# Học từ vựng từ tập huấn luyện và chuyển đổi văn bản thành ma trận TF-IDF\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Chỉ chuyển đổi tập kiểm tra bằng vectorizer đã được huấn luyện\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Kích thước ma trận TF-IDF tập huấn luyện: {X_train_vec.shape}\")\n",
        "print(f\"Kích thước ma trận TF-IDF tập kiểm tra: {X_test_vec.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59M9eojXvc9d"
      },
      "source": [
        "## **6. Xây dựng và huấn luyện Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8-PiKMQC4Rk",
        "outputId": "69513ccf-0268-4870-a68f-33b09289ff14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bắt đầu huấn luyện mô hình...\n",
            "Huấn luyện mô hình hoàn tất!\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo mô hình Logistic Regression\n",
        "# Logistic Regression là một lựa chọn tốt cho bài toán phân loại văn bản\n",
        "max_iter = 1000\n",
        "random_state = 42\n",
        "\n",
        "# Ghi log các tham số của model vào MLflow\n",
        "mlflow.log_param(\"model_max_iter\", max_iter)\n",
        "mlflow.log_param(\"random_state\", random_state)\n",
        "mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
        "\n",
        "model = LogisticRegression(max_iter=max_iter, random_state=random_state)\n",
        "\n",
        "# Huấn luyện mô hình trên dữ liệu đã được vector hóa\n",
        "print(\"\\nBắt đầu huấn luyện mô hình...\")\n",
        "model.fit(X_train_vec, y_train)\n",
        "print(\"Huấn luyện mô hình hoàn tất!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-4MoOwmvgM6"
      },
      "source": [
        "## **7. Đánh giá Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjXDNmuAC4OW",
        "outputId": "52bbc938-50be-4ac2-9f3b-3d6f9a2a8cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Báo cáo phân loại:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NEG       0.68      0.79      0.73      1334\n",
            "         NEU       0.48      0.35      0.41       940\n",
            "         POS       0.79      0.80      0.80      1363\n",
            "\n",
            "    accuracy                           0.68      3637\n",
            "   macro avg       0.65      0.65      0.64      3637\n",
            "weighted avg       0.67      0.68      0.67      3637\n",
            "\n",
            "Độ chính xác tổng thể (Accuracy): 0.6835\n"
          ]
        }
      ],
      "source": [
        "# Dự đoán nhãn trên tập kiểm tra\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# In báo cáo phân loại\n",
        "print(\"\\nBáo cáo phân loại:\")\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Ghi log các metrics chi tiết vào MLflow\n",
        "mlflow.log_metric(\"accuracy\", accuracy_score(y_test, y_pred))\n",
        "# for label, metrics in report.items():\n",
        "#     if isinstance(metrics, dict):\n",
        "#         for metric_name, value in metrics.items():\n",
        "#             mlflow.log_metric(f\"{label}_{metric_name}\", value)\n",
        "\n",
        "# In độ chính xác tổng thể\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Độ chính xác tổng thể (Accuracy): {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zm4jyfhvlE2"
      },
      "source": [
        "## **8. Xuất Model và Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tên của mô hình sẽ xuất hiện trong Model Registry\n",
        "model_name = \"EmotionTextClassifier\"\n",
        "\n",
        "# Lưu model (Logistic Regression) vào MLflow dưới dạng artifact\n",
        "# và đăng ký vào Model Registry\n",
        "mlflow.sklearn.log_model(\n",
        "    sk_model=model,\n",
        "    artifact_path=\"sentiment_model\", # Đường dẫn trong artifact store cho run này\n",
        "    registered_model_name=model_name # Tên mô hình trong Model Registry\n",
        ")\n",
        "print(f\"\\nModel '{model_name}' đã được lưu và đăng ký vào MLflow.\")\n",
        "\n",
        "# Lưu vectorizer (TfidfVectorizer) vào MLflow dưới dạng artifact\n",
        "# MLflow không có 'flavor' riêng cho vectorizer, nên ta dùng joblib và log như artifact bình thường\n",
        "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "mlflow.log_artifact(\"vectorizer.pkl\", artifact_path=\"sentiment_model\")\n",
        "os.remove(\"vectorizer.pkl\") # Xóa file tạm sau khi đã log\n",
        "print(f\"Vectorizer đã được lưu vào MLflow artifacts.\")\n",
        "\n",
        "# Lưu báo cáo phân loại dưới dạng file text làm artifact\n",
        "with open(\"classification_report.txt\", \"w\") as f:\n",
        "    f.write(classification_report(y_test, y_pred))\n",
        "mlflow.log_artifact(\"classification_report.txt\")\n",
        "os.remove(\"classification_report.txt\")\n",
        "\n",
        "\n",
        "print(f\"MLflow Run '{active_run.info.run_name}' (ID: {run_id}) đã hoàn tất!\")\n",
        "print(f\"Bạn có thể xem chi tiết run tại: {mlflow.get_tracking_uri()}/#/experiments/{active_run.info.experiment_id}/runs/{run_id}\")\n",
        "print(f\"Artifacts của run này được lưu tại: {active_run.info.artifact_uri}\")\n",
        "\n",
        "# --- KẾT THÚC MLFLOW RUN ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPhWyuR5C4LR",
        "outputId": "807a40ff-2f33-4a2f-f4f0-1457d81648fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model đã được lưu tại: model/model.pkl\n",
            "Vectorizer đã được lưu tại: model/vectorizer.pkl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Tạo thư mục 'model' nếu chưa tồn tại\n",
        "output_dir = 'model'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Định nghĩa đường dẫn để lưu model và vectorizer\n",
        "model_path = os.path.join(output_dir, 'model.pkl')\n",
        "vectorizer_path = os.path.join(output_dir, 'vectorizer.pkl')\n",
        "\n",
        "# Lưu model đã huấn luyện\n",
        "joblib.dump(model, model_path)\n",
        "print(f\"\\nModel đã được lưu tại: {model_path}\")\n",
        "\n",
        "# Lưu vectorizer đã huấn luyện\n",
        "joblib.dump(vectorizer, vectorizer_path)\n",
        "print(f\"Vectorizer đã được lưu tại: {vectorizer_path}\")\n",
        "\n",
        "# %% [markdown]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljnnueU2vvOC"
      },
      "source": [
        "## **9. Ví dụ sử dụng Model đã lưu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n--- Ví dụ sử dụng Model đã lưu từ MLflow ---\")\n",
        "\n",
        "# Tải lại model và vectorizer từ MLflow (sử dụng tên từ Model Registry)\n",
        "# Tải phiên bản mới nhất ở giai đoạn Production (hoặc Staging, None)\n",
        "# Bạn có thể chỉ định version cụ thể: \"models:/EmotionTextClassifier/1\"\n",
        "try:\n",
        "    loaded_model_from_mlflow = mlflow.pyfunc.load_model(f\"models/{model_name}/Production\")\n",
        "    print(f\"Đã tải model '{model_name}' từ MLflow Model Registry (Production).\")\n",
        "except Exception as e:\n",
        "    print(f\"Không thể tải model từ giai đoạn Production: {e}\")\n",
        "    print(f\"Thử tải phiên bản mới nhất không theo giai đoạn: models:/{model_name}/latest\")\n",
        "    loaded_model_from_mlflow = mlflow.pyfunc.load_model(f\"models:/{model_name}/latest\")\n",
        "    print(f\"Đã tải model '{model_name}' từ MLflow Model Registry (latest version).\")\n",
        "\n",
        "\n",
        "# Để tải vectorizer, bạn cần truy cập artifact_uri của run đã log nó.\n",
        "# Trong môi trường thực tế, bạn sẽ cần biết run_id của run đã log vectorizer đó.\n",
        "# Để đơn giản cho ví dụ này, chúng ta sẽ tải lại nó từ file tạm nếu có,\n",
        "# HOẶC bạn cần vào MLflow UI, tìm run tương ứng và sao chép artifact URI của vectorizer.pkl\n",
        "# Giả sử chúng ta đang ở một run khác, để tải vectorizer đã lưu:\n",
        "# Bạn cần tìm artifact_uri của run đã lưu vectorizer đó.\n",
        "# Ví dụ: loaded_vectorizer_from_mlflow = joblib.load(mlflow.artifacts.download_artifacts(artifact_uri=\"runs:/<RUN_ID_CUA_RUN_TRUOC>/sentiment_model/vectorizer.pkl\"))\n",
        "# Vì trong ví dụ này model và vectorizer được log trong cùng 1 run,\n",
        "# chúng ta có thể tái sử dụng 'run_id' từ 'active_run' nếu muốn tải lại ngay.\n",
        "# Nhưng thực tế sau này, bạn sẽ tải chúng trong một script riêng, dựa vào run_id.\n",
        "\n",
        "# Để tải vectorizer từ artifact của run hiện tại (cho ví dụ tức thì)\n",
        "try:\n",
        "    vectorizer_artifact_path = mlflow.artifacts.download_artifacts(\n",
        "        run_id=run_id, # Sử dụng run_id của run hiện tại\n",
        "        artifact_path=\"sentiment_model/vectorizer.pkl\"\n",
        "    )\n",
        "    loaded_vectorizer_from_mlflow = joblib.load(vectorizer_artifact_path)\n",
        "    print(\"Đã tải vectorizer từ MLflow artifacts.\")\n",
        "except Exception as e:\n",
        "    print(f\"Lỗi khi tải vectorizer từ MLflow artifacts: {e}\")\n",
        "    print(\"Vui lòng đảm bảo vectorizer.pkl tồn tại trong artifact store của run này.\")\n",
        "    exit() # Thoát nếu không thể tải vectorizer\n",
        "\n",
        "# Thử dự đoán với một câu bình luận mới\n",
        "new_comments = [\n",
        "    \"Sản phẩm rất tốt, tôi rất ưng ý!\",\n",
        "    \"Chất lượng kém, không đáng tiền chút nào.\",\n",
        "    \"Bình thường\",\n",
        "    \"Chán, dùng như hạch\",\n",
        "    \"Tuyệt vời, tôi rất ưng ý!\",\n",
        "    \"nhàu nát, tôi sẽ trả lại\",\n",
        "    \"tệ, khống đáng mua\",\n",
        "    \"tạm ổn\",\n",
        "    \"good, sẽ mua thêm cái nữa\",\n",
        "    \"tuyệt vời, sẽ rủ người thân mua\"\n",
        "]\n",
        "\n",
        "# Vector hóa các bình luận mới\n",
        "new_comments_vec = loaded_vectorizer_from_mlflow.transform(new_comments)\n",
        "\n",
        "# Dự đoán nhãn\n",
        "predictions = loaded_model_from_mlflow.predict(new_comments_vec)\n",
        "\n",
        "print(\"\\nDự đoán cho các bình luận mới (tải từ MLflow):\")\n",
        "for comment, pred_label in zip(new_comments, predictions):\n",
        "    print(f\"- '{comment}' -> Nhãn dự đoán: {pred_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhLeCVKwC4GR",
        "outputId": "8b36b89f-3546-4153-a288-06b1f8762fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dự đoán cho các bình luận mới:\n",
            "- 'Sản phẩm rất tốt, tôi rất ưng ý!' -> Nhãn dự đoán: POS\n",
            "- 'Chất lượng kém, không đáng tiền chút nào.' -> Nhãn dự đoán: NEG\n",
            "- 'Bình thường' -> Nhãn dự đoán: NEU\n",
            "- 'Chán, dùng như hạch' -> Nhãn dự đoán: NEG\n",
            "- 'Tuyệt vời, tôi rất ưng ý!' -> Nhãn dự đoán: POS\n",
            "- 'nhàu nát, tôi sẽ trả lạitệ, khống đáng mua' -> Nhãn dự đoán: NEG\n",
            "- 'tạm ổn' -> Nhãn dự đoán: NEU\n",
            "- 'good, sẽ mua thêm cái nữa' -> Nhãn dự đoán: POS\n",
            "- 'tuyệt vời, sẽ rủ người thân mua' -> Nhãn dự đoán: POS\n"
          ]
        }
      ],
      "source": [
        "# Tải lại model và vectorizer để kiểm tra\n",
        "loaded_model = joblib.load(model_path)\n",
        "loaded_vectorizer = joblib.load(vectorizer_path)\n",
        "\n",
        "# Thử dự đoán với một câu bình luận mới\n",
        "new_comments = [\n",
        "    \"Sản phẩm rất tốt, tôi rất ưng ý!\",\n",
        "    \"Chất lượng kém, không đáng tiền chút nào.\",\n",
        "    \"Bình thường\",\n",
        "    \"Chán, dùng như hạch\",\n",
        "    \"Tuyệt vời, tôi rất ưng ý!\",\n",
        "    \"nhàu nát, tôi sẽ trả lại\"\n",
        "    \"tệ, khống đáng mua\",\n",
        "    \"tạm ổn\",\n",
        "    \"good, sẽ mua thêm cái nữa\",\n",
        "    \"tuyệt vời, sẽ rủ người thân mua\"\n",
        "]\n",
        "\n",
        "# Vector hóa các bình luận mới\n",
        "new_comments_vec = loaded_vectorizer.transform(new_comments)\n",
        "\n",
        "# Dự đoán nhãn\n",
        "predictions = loaded_model.predict(new_comments_vec)\n",
        "\n",
        "print(\"\\nDự đoán cho các bình luận mới:\")\n",
        "for comment, pred_label in zip(new_comments, predictions):\n",
        "    print(f\"- '{comment}' -> Nhãn dự đoán: {pred_label}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
